{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from sqlite3 import Error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "versions_v2_02091742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content:\n",
    "\n",
    "- ## [Functions](#Functions)\n",
    "- ## [Joining](#Joining):\n",
    "    - [Strategy](#Strategy)\n",
    "    - [Feature engineering](#feature-engineering):\n",
    "        - [Create meaningful columns](#create-meaningful-columns)\n",
    "        - [Cleaning dataframe](#cleaning-dataframe)\n",
    "        - [Missing values](#missing-values)\n",
    "\n",
    "- ## [Database](#Database):\n",
    "\n",
    "Acronyms and Definition:\n",
    "\n",
    "+ fsq = FourSquare (API)\n",
    "+ yelp = Yelp (API)\n",
    "+ poi(s) = Point Of Interest(s)\n",
    "+ stations = Bike rental station (Bixi - Montr√©al, Qc, Canada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to rename columns in a DataFrame\n",
    "def rename_columns(df, rename_dict):\n",
    "    df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from sources\n",
    "stations = pd.read_csv('../data/stations.csv', index_col=None)\n",
    "fsq_pois = pd.read_csv('../data/fsq_businesses.csv', index_col=None)\n",
    "yelp_pois = pd.read_csv('../data/yelp_businesses.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "- Create a combined dataframe with both Yelp and FourSquare data for the creation of the SQLite database.\n",
    "<br>See [Database](#Database) section.\n",
    "- Filter the combined date with Yelp API only for the first model, and both for the second model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create meaningful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change some columns name to match both data\n",
    "# FSQ\n",
    "fsq_rename_dict = {\n",
    "    'fsq_id': 'api_number'\n",
    "}\n",
    "\n",
    "# Yelp:\n",
    "yelp_rename_dict = {\n",
    "    'id': 'api_number',\n",
    "    'category_alias': 'category_name',\n",
    "    'rating': 'original_rating',\n",
    "    'scaled_rating': 'rating'\n",
    "}\n",
    "\n",
    "# Apply rename_columns to both DataFrames\n",
    "rename_columns(fsq_pois, fsq_rename_dict)\n",
    "rename_columns(yelp_pois, yelp_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create api_name to differentiate the POI provenance and api_number\n",
    "fsq_pois['api_name'] = \"FourSquare\"\n",
    "yelp_pois['api_name'] = \"Yelp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create POI id for easier reference using the rank method to assign unique integers to each unique api_number\n",
    "\n",
    "# Yelp:\n",
    "yelp_pois['poi_id'] = yelp_pois['api_number'].rank(method='dense').astype(int) - 1 # start from 0\n",
    "\n",
    "# Register the last poi_id\n",
    "starting_number = yelp_pois['poi_id'].max()\n",
    "\n",
    "# FSQ:\n",
    "fsq_pois['poi_id'] = fsq_pois['api_number'].rank(method='dense').astype(int) + starting_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424\n",
      "1527    2424\n",
      "Name: poi_id, dtype: int64\n",
      "34100    2425\n",
      "Name: poi_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "print(starting_number)\n",
    "print(yelp_pois['poi_id'].sort_values().tail(1))\n",
    "print(fsq_pois['poi_id'].sort_values().head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59349 entries, 0 to 59348\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   api_number     59349 non-null  object \n",
      " 1   name           59349 non-null  object \n",
      " 2   s_lat          59349 non-null  float64\n",
      " 3   s_lon          59349 non-null  float64\n",
      " 4   p_lat          59349 non-null  float64\n",
      " 5   p_lon          59349 non-null  float64\n",
      " 6   category_id    59349 non-null  int64  \n",
      " 7   category_name  59349 non-null  object \n",
      " 8   distance       59349 non-null  int64  \n",
      " 9   rating         39961 non-null  float64\n",
      " 10  popularity     51230 non-null  float64\n",
      " 11  price          43531 non-null  float64\n",
      " 12  station        59349 non-null  int64  \n",
      " 13  api_name       59349 non-null  object \n",
      " 14  poi_id         59349 non-null  int64  \n",
      "dtypes: float64(7), int64(4), object(4)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "fsq_pois.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22394 entries, 0 to 22393\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   api_number       22394 non-null  object \n",
      " 1   name             22394 non-null  object \n",
      " 2   original_rating  22394 non-null  float64\n",
      " 3   price            17393 non-null  float64\n",
      " 4   review_count     22394 non-null  int64  \n",
      " 5   s_lat            22394 non-null  float64\n",
      " 6   s_lon            22394 non-null  float64\n",
      " 7   p_lat            22394 non-null  float64\n",
      " 8   p_lon            22394 non-null  float64\n",
      " 9   category_name    22394 non-null  object \n",
      " 10  distance         22394 non-null  int64  \n",
      " 11  rating           22394 non-null  float64\n",
      " 12  station          22394 non-null  int64  \n",
      " 13  api_name         22394 non-null  object \n",
      " 14  poi_id           22394 non-null  int64  \n",
      "dtypes: float64(7), int64(4), object(4)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yelp_pois.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset the index of both DataFrames\n",
    "fsq_pois.reset_index(drop=True, inplace=True)\n",
    "yelp_pois.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create combined dataframe\n",
    "combined_df = pd.concat([fsq_pois, yelp_pois], keys=['fsq_pois', 'yelp_pois'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_number</th>\n",
       "      <th>name</th>\n",
       "      <th>s_lat</th>\n",
       "      <th>s_lon</th>\n",
       "      <th>p_lat</th>\n",
       "      <th>p_lon</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>distance</th>\n",
       "      <th>rating</th>\n",
       "      <th>popularity</th>\n",
       "      <th>price</th>\n",
       "      <th>station</th>\n",
       "      <th>api_name</th>\n",
       "      <th>poi_id</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4cb240b8cbab236ae154af73</td>\n",
       "      <td>Restaurant Prima Luna</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617439</td>\n",
       "      <td>-73.593995</td>\n",
       "      <td>13236.0</td>\n",
       "      <td>Italian Restaurant</td>\n",
       "      <td>941</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e0b48221f6edc06be259aec</td>\n",
       "      <td>Salle D√©silets</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617818</td>\n",
       "      <td>-73.606000</td>\n",
       "      <td>10039.0</td>\n",
       "      <td>Music Venue</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e0b48221f6edc06be259aec</td>\n",
       "      <td>Salle D√©silets</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617818</td>\n",
       "      <td>-73.606000</td>\n",
       "      <td>11130.0</td>\n",
       "      <td>Office Building</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ea9b28cb803cf1ffacd7c0d</td>\n",
       "      <td>Caf√© l'Exil</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617214</td>\n",
       "      <td>-73.604961</td>\n",
       "      <td>13034.0</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ea9b28cb803cf1ffacd7c0d</td>\n",
       "      <td>Caf√© l'Exil</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617214</td>\n",
       "      <td>-73.604961</td>\n",
       "      <td>13035.0</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 api_number                   name    s_lat      s_lon  \\\n",
       "0  4cb240b8cbab236ae154af73  Restaurant Prima Luna  45.6175 -73.606011   \n",
       "1  4e0b48221f6edc06be259aec         Salle D√©silets  45.6175 -73.606011   \n",
       "2  4e0b48221f6edc06be259aec         Salle D√©silets  45.6175 -73.606011   \n",
       "3  4ea9b28cb803cf1ffacd7c0d            Caf√© l'Exil  45.6175 -73.606011   \n",
       "4  4ea9b28cb803cf1ffacd7c0d            Caf√© l'Exil  45.6175 -73.606011   \n",
       "\n",
       "       p_lat      p_lon  category_id       category_name  distance  rating  \\\n",
       "0  45.617439 -73.593995      13236.0  Italian Restaurant       941     7.4   \n",
       "1  45.617818 -73.606000      10039.0         Music Venue        19     NaN   \n",
       "2  45.617818 -73.606000      11130.0     Office Building        19     NaN   \n",
       "3  45.617214 -73.604961      13034.0                Caf√©        79     NaN   \n",
       "4  45.617214 -73.604961      13035.0         Coffee Shop        79     NaN   \n",
       "\n",
       "   popularity  price  station    api_name  poi_id  original_rating  \\\n",
       "0       0.985    1.0      790  FourSquare    4078              NaN   \n",
       "1       0.969    NaN      790  FourSquare    4392              NaN   \n",
       "2       0.969    NaN      790  FourSquare    4392              NaN   \n",
       "3       0.869    1.0      790  FourSquare    4519              NaN   \n",
       "4       0.869    1.0      790  FourSquare    4519              NaN   \n",
       "\n",
       "   review_count  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81743 entries, 0 to 81742\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   api_number       81743 non-null  object \n",
      " 1   name             81743 non-null  object \n",
      " 2   s_lat            81743 non-null  float64\n",
      " 3   s_lon            81743 non-null  float64\n",
      " 4   p_lat            81743 non-null  float64\n",
      " 5   p_lon            81743 non-null  float64\n",
      " 6   category_id      59349 non-null  float64\n",
      " 7   category_name    81743 non-null  object \n",
      " 8   distance         81743 non-null  int64  \n",
      " 9   rating           62355 non-null  float64\n",
      " 10  popularity       51230 non-null  float64\n",
      " 11  price            60924 non-null  Int64  \n",
      " 12  station          81743 non-null  int64  \n",
      " 13  api_name         81743 non-null  object \n",
      " 14  poi_id           81743 non-null  int64  \n",
      " 15  original_rating  22394 non-null  float64\n",
      " 16  review_count     22394 non-null  float64\n",
      "dtypes: Int64(1), float64(9), int64(3), object(4)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81743 entries, 0 to 81742\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   api_number       81743 non-null  object \n",
      " 1   name             81743 non-null  object \n",
      " 2   s_lat            81743 non-null  float64\n",
      " 3   s_lon            81743 non-null  float64\n",
      " 4   p_lat            81743 non-null  float64\n",
      " 5   p_lon            81743 non-null  float64\n",
      " 6   category_id      59349 non-null  Int64  \n",
      " 7   category_name    81743 non-null  object \n",
      " 8   distance         81743 non-null  int64  \n",
      " 9   rating           62355 non-null  float64\n",
      " 10  popularity       51230 non-null  float64\n",
      " 11  price            60924 non-null  Int64  \n",
      " 12  station          81743 non-null  int64  \n",
      " 13  api_name         81743 non-null  object \n",
      " 14  poi_id           81743 non-null  int64  \n",
      " 15  original_rating  22394 non-null  float64\n",
      " 16  review_count     22394 non-null  Int64  \n",
      "dtypes: Int64(3), float64(7), int64(3), object(4)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df['category_id'] = combined_df['category_id'].astype('Int64')\n",
    "combined_df['price'] = combined_df['price'].astype('Int64')\n",
    "combined_df['review_count'] = combined_df['review_count'].astype('Int64')\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_number</th>\n",
       "      <th>name</th>\n",
       "      <th>s_lat</th>\n",
       "      <th>s_lon</th>\n",
       "      <th>p_lat</th>\n",
       "      <th>p_lon</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>distance</th>\n",
       "      <th>rating</th>\n",
       "      <th>popularity</th>\n",
       "      <th>price</th>\n",
       "      <th>station</th>\n",
       "      <th>api_name</th>\n",
       "      <th>poi_id</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4cb240b8cbab236ae154af73</td>\n",
       "      <td>Restaurant Prima Luna</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617439</td>\n",
       "      <td>-73.593995</td>\n",
       "      <td>13236</td>\n",
       "      <td>Italian Restaurant</td>\n",
       "      <td>941</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e0b48221f6edc06be259aec</td>\n",
       "      <td>Salle D√©silets</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617818</td>\n",
       "      <td>-73.606000</td>\n",
       "      <td>10039</td>\n",
       "      <td>Music Venue</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e0b48221f6edc06be259aec</td>\n",
       "      <td>Salle D√©silets</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617818</td>\n",
       "      <td>-73.606000</td>\n",
       "      <td>11130</td>\n",
       "      <td>Office Building</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ea9b28cb803cf1ffacd7c0d</td>\n",
       "      <td>Caf√© l'Exil</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617214</td>\n",
       "      <td>-73.604961</td>\n",
       "      <td>13034</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ea9b28cb803cf1ffacd7c0d</td>\n",
       "      <td>Caf√© l'Exil</td>\n",
       "      <td>45.6175</td>\n",
       "      <td>-73.606011</td>\n",
       "      <td>45.617214</td>\n",
       "      <td>-73.604961</td>\n",
       "      <td>13035</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>FourSquare</td>\n",
       "      <td>4519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 api_number                   name    s_lat      s_lon  \\\n",
       "0  4cb240b8cbab236ae154af73  Restaurant Prima Luna  45.6175 -73.606011   \n",
       "1  4e0b48221f6edc06be259aec         Salle D√©silets  45.6175 -73.606011   \n",
       "2  4e0b48221f6edc06be259aec         Salle D√©silets  45.6175 -73.606011   \n",
       "3  4ea9b28cb803cf1ffacd7c0d            Caf√© l'Exil  45.6175 -73.606011   \n",
       "4  4ea9b28cb803cf1ffacd7c0d            Caf√© l'Exil  45.6175 -73.606011   \n",
       "\n",
       "       p_lat      p_lon  category_id       category_name  distance  rating  \\\n",
       "0  45.617439 -73.593995        13236  Italian Restaurant       941     7.4   \n",
       "1  45.617818 -73.606000        10039         Music Venue        19     NaN   \n",
       "2  45.617818 -73.606000        11130     Office Building        19     NaN   \n",
       "3  45.617214 -73.604961        13034                Caf√©        79     NaN   \n",
       "4  45.617214 -73.604961        13035         Coffee Shop        79     NaN   \n",
       "\n",
       "   popularity  price  station    api_name  poi_id  original_rating  \\\n",
       "0       0.985      1      790  FourSquare    4078              NaN   \n",
       "1       0.969   <NA>      790  FourSquare    4392              NaN   \n",
       "2       0.969   <NA>      790  FourSquare    4392              NaN   \n",
       "3       0.869      1      790  FourSquare    4519              NaN   \n",
       "4       0.869      1      790  FourSquare    4519              NaN   \n",
       "\n",
       "   review_count  \n",
       "0          <NA>  \n",
       "1          <NA>  \n",
       "2          <NA>  \n",
       "3          <NA>  \n",
       "4          <NA>  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "Let see if we can find a way to reconnect the same POI from both API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station                         name      p_lat      p_lon  poi_id  \\\n",
      "0      564  Lasalle Drive-In Restaurant  45.415116 -73.621609    3479   \n",
      "1      564  Lasalle Drive-In Restaurant  45.415137 -73.621927     715   \n",
      "2      564            Capitales Burgers  45.417063 -73.620510    2119   \n",
      "3      564            Capitales Burgers  45.417193 -73.620034    5216   \n",
      "4      564               Ayo Restaurant  45.420987 -73.631326    4773   \n",
      "5      564               Ayo Restaurant  45.421010 -73.631280       6   \n",
      "6      559             Grillades Torino  45.421681 -73.493897     195   \n",
      "7      531                   Le Saucier  45.422707 -73.612000     238   \n",
      "8      417           Buffalo Bill Wings  45.423378 -73.641848    2958   \n",
      "9      417                 Double Pizza  45.423480 -73.641740    1372   \n",
      "\n",
      "     api_name                api_number  \n",
      "0  FourSquare  4b884e1ff964a520f1ed31e3  \n",
      "1        Yelp    IaUx8KmmqY2Z-58d_E0_mg  \n",
      "2        Yelp    sWFGuy-45ZGz4g9hn4ZVyw  \n",
      "3  FourSquare  55c6637d498eff6d60471a8c  \n",
      "4  FourSquare  50be8855e4b0c56b41b2aecc  \n",
      "5        Yelp    -DXRTcIIFSDFaec9SozG3A  \n",
      "6        Yelp    4W8aG-VqWKJaan3jhrxxAg  \n",
      "7        Yelp    5jNkYnWI2yp0RYzgdn5wzA  \n",
      "8  FourSquare  44e4f1d847b74f4462370945  \n",
      "9        Yelp    Zw5EbC4ICkK3UP9iaKtn_g  \n"
     ]
    }
   ],
   "source": [
    "# Filter unique api_number, sort per p_lat, p_lon\n",
    "sorted_df = (\n",
    "    combined_df[['station', 'name', 'p_lat', 'p_lon', 'poi_id', 'api_name', 'api_number']]\n",
    "    .drop_duplicates(subset=['api_number'])\n",
    "    .sort_values(['p_lat', 'p_lon', 'poi_id'])\n",
    ")\n",
    "filtered_df = sorted_df[sorted_df.duplicated(subset='name', keep=False)].reset_index(drop=True).copy()\n",
    "print(filtered_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The locations slightly diverge. We could try to reassign the Min(poi_id) (the one created for Yelp) when the name is similar within the same station and next to each other (p.lat, p_lon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station                         name      p_lat      p_lon  poi_id  \\\n",
      "0      564  Lasalle Drive-In Restaurant  45.415116 -73.621609    3479   \n",
      "1      564  Lasalle Drive-In Restaurant  45.415137 -73.621927     715   \n",
      "2      564            Capitales Burgers  45.417063 -73.620510    2119   \n",
      "3      564            Capitales Burgers  45.417193 -73.620034    5216   \n",
      "4      564               Ayo Restaurant  45.420987 -73.631326    4773   \n",
      "5      564               Ayo Restaurant  45.421010 -73.631280       6   \n",
      "6      559             Grillades Torino  45.421681 -73.493897     195   \n",
      "7      531                   Le Saucier  45.422707 -73.612000     238   \n",
      "8      417           Buffalo Bill Wings  45.423378 -73.641848    2958   \n",
      "9      417                 Double Pizza  45.423480 -73.641740    1372   \n",
      "\n",
      "     api_name                api_number  updated_poi_id  \n",
      "0  FourSquare  4b884e1ff964a520f1ed31e3            3479  \n",
      "1        Yelp    IaUx8KmmqY2Z-58d_E0_mg             715  \n",
      "2        Yelp    sWFGuy-45ZGz4g9hn4ZVyw            2119  \n",
      "3  FourSquare  55c6637d498eff6d60471a8c            2119  \n",
      "4  FourSquare  50be8855e4b0c56b41b2aecc            4773  \n",
      "5        Yelp    -DXRTcIIFSDFaec9SozG3A               6  \n",
      "6        Yelp    4W8aG-VqWKJaan3jhrxxAg             195  \n",
      "7        Yelp    5jNkYnWI2yp0RYzgdn5wzA             238  \n",
      "8  FourSquare  44e4f1d847b74f4462370945            2958  \n",
      "9        Yelp    Zw5EbC4ICkK3UP9iaKtn_g            1372  \n"
     ]
    }
   ],
   "source": [
    "filtered_df['updated_poi_id'] = filtered_df['poi_id']\n",
    "df = filtered_df\n",
    "\n",
    "# Iterate over rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if index < len(df) - 1:\n",
    "        # Check if the current row and the next row have similar 'name', 'station', and are adjacent\n",
    "        pattern = re.compile(re.escape(row['name']), re.IGNORECASE)\n",
    "\n",
    "        # Check if the current row's 'name' or the next row's 'name' matches the pattern\n",
    "        if (\n",
    "            (pattern.search(row['name']) or pattern.search(df.at[index + 1, 'name']))\n",
    "            and row['station'] == df.at[index + 1, 'station']\n",
    "        ):\n",
    "            # Update the 'updated_poi_id' column with the minimum poi_id value\n",
    "            df.at[index + 1, 'updated_poi_id'] = min(row['poi_id'], df.at[index + 1, 'poi_id'])\n",
    "print(filtered_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets validate name of same poi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to select rows where 'api_name' is different\n",
    "filtered_df = combined_df[combined_df['api_name'] != combined_df['api_name'].shift()][['poi_id', 'name']]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_yelp = combined_df[combined_df['api_name'] == \"Yelp\"]['poi_id'].max()\n",
    "print(combined_df['api_number'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data for SQLite3 database\n",
    "combined_df.to_csv('../data/yelp_and_fsq.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the POI per stations with their chacteristics\n",
    "grouped_df = combined_df[['station','distance', 'review_count', 'rating', 'popularity', 'price']].groupby('station').mean().sort_values('station')\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with stations\n",
    "merge_df = pd.merge(stations, grouped_df, on='station', how='outer') # Outer, not to lose any station with no data.\n",
    "print(merge_df.head())\n",
    "print(merge_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "bike_rentals = merge_df[['station', 'total_bikes', 'review_count', 'rating', 'popularity', 'price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like we have some stations with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the nulls\n",
    "print(bike_rentals[bike_rentals.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of removing these stations (with a good amount of bikes), we could replace the characteristics with the mean of similar stations with same quantity of bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to replace NaN value with mean when total_bikes is similar\n",
    "def replace_nan_with_mean(row):\n",
    "    df = bike_rentals\n",
    "    total_bikes = row['total_bikes']\n",
    "    bike_range = 5\n",
    "    \n",
    "    similar_rows = df[(df['total_bikes'] >= total_bikes - bike_range) & \n",
    "                      (df['total_bikes'] <= total_bikes + bike_range)]\n",
    "    \n",
    "    mean_values = similar_rows.mean()\n",
    "    row = row.fillna(mean_values)\n",
    "    return row\n",
    "\n",
    "# Apply the function to rows with NaN values\n",
    "new_bike_rentals = bike_rentals.apply(lambda row: replace_nan_with_mean(row) if row.isnull().any() else row, axis=1)\n",
    "\n",
    "print(new_bike_rentals[new_bike_rentals.isnull().any(axis=1)])\n",
    "print(new_bike_rentals.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bike_rentals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean dataframe\n",
    "new_bike_rentals.to_csv('../data/bike_rentals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of each variables (filtered data)\n",
    "plt.figure(figsize=(12, 8))\n",
    "new_bike_rentals.hist(bins=20, alpha=0.8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVERVIEW\n",
    "- Dependant variable:\n",
    "    + Total_bikes seems to have some outliers with a lot of bikes compare to the other station\n",
    "- Independant variables:\n",
    "    + Rating is not normally distributed, and we could remove the stations below a rating of 6.\n",
    "    + Popularity looks more like a normal distributon\n",
    "    + Price still have some outliers above 2. Removing them would center the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "filtered_rentals[['total_bikes', 'rating', 'popularity', 'price']].boxplot()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "filtered_rentals = (\n",
    "    filtered_rentals[\n",
    "        (filtered_rentals['total_bikes'].between(10, 50)) &\n",
    "        (filtered_rentals['rating'] > 6) &\n",
    "        (filtered_rentals['price'] < 2)\n",
    "    ]\n",
    ")\n",
    "filtered_rentals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVERVIEW:\n",
    "Looks like all the means now are close to the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the merged data\n",
    "filtered_rentals.to_csv('../data/bike_rentals.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationship with the dependant variable\n",
    "ind_var = ['rating', 'popularity', 'price']\n",
    "dep_var = ['total_bikes']\n",
    "\n",
    "# Create a DataFrame with the variables\n",
    "vars_to_plot = ind_var + dep_var\n",
    "data_to_plot = filtered_rentals[vars_to_plot]\n",
    "\n",
    "# Create a pair plot\n",
    "g = sns.pairplot(data_to_plot, kind='reg', plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.3}})\n",
    "g.map_lower(sns.scatterplot, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVERVIEW\n",
    "- The only 'visible' relationship between independant variables is the one between rating and price, thought not strong. We could choose either of them for the modelling.\n",
    "- As for the relationship between 'total_bikes\" and all the independant variables, they are all similar, showing a weak positve relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "correlation_matrix = filtered_rentals[['total_bikes', 'rating', 'popularity', 'price']].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVERVIEW\n",
    "- As expected, rating and price have the strongest correlation. We will use rating for the model since the price is almost the same scale (1 to 2: inexpensive) for every POI.\n",
    "- All independant variable have the same weak (25%) correlation with the dependant variable. Not really good for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions and connection info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection function\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query function\n",
    "def execute_query(queries, cursor, data=None, print_message=True):\n",
    "    try:\n",
    "        for query in queries:\n",
    "            if data:\n",
    "                cursor.execute(query, data)\n",
    "            else:\n",
    "                cursor.execute(query)\n",
    "        \n",
    "        # Commit only if all statements succeeded\n",
    "        cursor.connection.commit()\n",
    "        \n",
    "        if print_message:\n",
    "            print(\"Queries executed successfully\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        # Rollback the transaction in case of error\n",
    "        cursor.connection.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1a: Create tables<br>\n",
    "- **stations**: to hold information related to the stations location in the city along with their total bikes\n",
    "- **pois**: to hold the information about each POI (including rating, popularity, price)\n",
    "- **categories**: simulates the api category for Foursquare\n",
    "- **poi_category**: joining table for poi and categories (many-to-many)\n",
    "- **prices**: to holds the definition of the prices number\n",
    "- **poi_detail**: creates the relation between data (station, poi_id, distance to the station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE queries in related order\n",
    "create_table_queries = [\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stations (\n",
    "  station_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  station_name VARCHAR NOT NULL,\n",
    "  s_lat FLOAT NOT NULL,\n",
    "  s_lon FLOAT NOT NULL,\n",
    "  total_bikes INTEGER NOT NULL\n",
    ");\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS categories (\n",
    "  category_id INTEGER PRIMARY KEY,\n",
    "  category_name VARCHAR NOT NULL\n",
    ");\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prices (\n",
    "  price INTEGER PRIMARY KEY,\n",
    "  price_name VARCHAR NOT NULL\n",
    ");\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS pois (\n",
    "  poi_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  api_number VARCHAR NOT NULL,\n",
    "  api_name VARCHAR NOT NULL,\n",
    "  poi_name VARCHAR NOT NULL,\n",
    "  p_lat FLOAT NOT NULL,\n",
    "  p_lon FLOAT NOT NULL,\n",
    "  rating INTEGER,\n",
    "  popularity FLOAT,\n",
    "  price INTEGER,\n",
    "  FOREIGN KEY (price) REFERENCES prices(price)\n",
    ");\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS poi_category (\n",
    "  poi_id INTEGER NOT NULL,\n",
    "  category_id INTEGER NOT NULL,\n",
    "  PRIMARY KEY (poi_id, category_id),\n",
    "  FOREIGN KEY (poi_id) REFERENCES pois(poi_id),\n",
    "  FOREIGN KEY (category_id) REFERENCES categories(category_id)\n",
    ");\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS poi_detail (\n",
    "  data_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  station_id INTEGER NOT NULL,\n",
    "  poi_id INTEGER NOT NULL,\n",
    "  to_station_m INTEGER NOT NULL,\n",
    "  FOREIGN KEY (station_id) REFERENCES stations(station_id),\n",
    "  FOREIGN KEY (poi_id) REFERENCES pois(poi_id)\n",
    ");\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection and cursor\n",
    "conn = create_connection('../data/mtl_bike_rentals.sqlite')\n",
    "# Create cursor\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to create the tables\n",
    "execute_query(create_table_queries, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1b: Inserts data in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to execute inserts\n",
    "def execute_inserts(table, query, cursor):\n",
    "\n",
    "    # Convert DataFrame rows to list of dictionaries\n",
    "    my_list = table.to_dict(orient='records')\n",
    "\n",
    "    # Iterate through the list of dictionaries and insert data\n",
    "    for row in my_list:\n",
    "        try:\n",
    "            execute_query(query, cursor, row, print_message=False)\n",
    "\n",
    "        except sqlite3.Error as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            \n",
    "    print(\"Queries executed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "insert_stations = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  stations (station_id, station_name, s_lat, s_lon, total_bikes)\n",
    "VALUES\n",
    "  (:station, :station_name, :latitude, :longitude, :total_bikes);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(stations, insert_stations, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "categories = (\n",
    "    fsq_pois[['category_id', 'category_name']]\n",
    "    .drop_duplicates(subset='category_id')\n",
    "    .sort_values('category_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "insert_categories = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  categories (category_id, category_name)\n",
    "VALUES\n",
    "  (:category_id, :category_name);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(categories, insert_categories, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "\n",
    "price = {\n",
    "    1: 'Cheap',\n",
    "    2: 'Moderate',\n",
    "    3: 'Expensive',\n",
    "    4: 'Very Expensive',\n",
    "}\n",
    "prices = pd.DataFrame({'price': list(price.keys()), 'price_name': list(price.values())})\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "insert_prices = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  prices (price, price_name)\n",
    "VALUES\n",
    "  (:price, :price_name);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(prices, insert_prices, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POIs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "\n",
    "pois = (\n",
    "    fsq_pois[['fsq_id', 'name', 'p_lat', 'p_lon', 'rating', 'popularity', 'price']]\n",
    "    .drop_duplicates(subset='fsq_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "api_name = 'FourSquare'\n",
    "pois.insert(loc=1, column='api_name', value=api_name)\n",
    "\n",
    "pois.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the relation between the index and the fsq_id (for the category_poi table later)\n",
    "\n",
    "poi_pk = pois[['fsq_id']].copy()\n",
    "poi_pk['index_number'] = pois.index\n",
    "\n",
    "poi_pk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "\n",
    "insert_pois = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  pois (api_number, api_name, poi_name, p_lat, p_lon, rating, popularity, price)\n",
    "VALUES\n",
    "  (:fsq_id, :api_name, :name, :p_lat, :p_lon, :rating, :popularity, :price);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(pois, insert_pois, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI_category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "fsq_cat = fsq_pois[['fsq_id', 'category_id']]\n",
    "\n",
    "poi_category = fsq_cat.merge(poi_pk, on='fsq_id', how='left') # poi_pk created in previous query\n",
    "poi_category.drop(columns='fsq_id', inplace=True)\n",
    "\n",
    "poi_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "insert_poi_category = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  poi_category (poi_id, category_id)\n",
    "VALUES\n",
    "  (:index_number, :category_id);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(poi_category, insert_poi_category, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "\n",
    "poi_detail = fsq_pois[['station', 'distance', 'fsq_id']].drop_duplicates()\n",
    "poi_detail = poi_detail.merge(poi_pk, on='fsq_id', how='left')\n",
    "poi_detail.drop(columns='fsq_id', inplace=True)\n",
    "\n",
    "poi_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "\n",
    "insert_poi_detail = [\n",
    "\"\"\"\n",
    "INSERT INTO\n",
    "  poi_detail (station_id, poi_id, to_station_m)\n",
    "VALUES\n",
    "  (:station, :index_number, :distance);\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Insert in table\n",
    "execute_inserts(poi_detail, insert_poi_detail, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection\n",
    "conn = sqlite3.connect('../data/mtl_bike_rentals.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data from db\n",
    "df_all = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        name\n",
    "    FROM\n",
    "        sqlite_master \n",
    "    WHERE\n",
    "        type ='table'\n",
    "        AND name NOT LIKE 'sqlite_%';\n",
    "    \"\"\", conn\n",
    ")\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for modeling and compare values to bike.rentals_csv (dataframe)\n",
    "\n",
    "df_rentals = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        s.station_name AS name,\n",
    "        s.station_id AS station,\n",
    "        AVG(s.total_bikes) as total_bikes,\n",
    "        AVG(pd.to_station_m) AS avg_distance_to_station_m,\n",
    "        AVG(p.rating) AS avg_rating,\n",
    "        AVG(p.popularity) AS avg_popularity,\n",
    "        AVG(p.price) AS avg_price\n",
    "    FROM\n",
    "        stations s\n",
    "    JOIN poi_detail pd USING(station_id)\n",
    "    JOIN pois p USING(poi_id)\n",
    "    JOIN poi_category USING(poi_id)\n",
    "    JOIN categories c USING(category_id)\n",
    "    GROUP BY 1, 2\n",
    "    HAVING\n",
    "        total_bikes BETWEEN 10 AND 50\n",
    "        AND avg_rating >= 6\n",
    "        AND avg_price <=2\n",
    "        AND avg_distance_to_station_m > 1000\n",
    "    ORDER BY 2\n",
    "    \"\"\", conn\n",
    ")\n",
    "\n",
    "print(df_rentals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rentals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for modeling and compare values to bike.rentals_csv (dataframe)\n",
    "\n",
    "df_stations = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT station_id, poi_id, to_station_m\n",
    "    FROM\n",
    "        poi_detail pd\n",
    "    WHERE\n",
    "        to_station_m > 10000\n",
    "    \"\"\", conn\n",
    ")\n",
    "\n",
    "print(df_stations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_lhl",
   "language": "python",
   "name": "dev_lhl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
